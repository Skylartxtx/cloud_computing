version: "3.3"

volumes:
    shared-workspace-project:
    project_hadoop_datanode1:
    project_hadoop_datanode2:
    project_hadoop_datanode3:
    project_hadoop_namenode:
    project_hadoop_historyserver:
    project_data:

networks:
    project-net:
        driver: bridge

services:
  project-namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: project-namenode
    networks:
      - "project-net"
    ports:
      - 10070:9870   # 避免与 cca3 冲突，改变端口
      - 10000:9000   # 避免与 cca3 冲突
    volumes:
      - project_hadoop_namenode:/hadoop/dfs/name
      - ./data:/home/data  # 挂载你的数据目录
    environment:
      - CLUSTER_NAME=project_cluster
    env_file:
      - ./hadoop.env

  project-resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: project-resourcemanager
    depends_on:
      - project-namenode
      - project-datanode1
      - project-datanode2
      - project-datanode3
    networks:
      - "project-net"
    ports:
      - 10089:8088  # 避免与 cca3 冲突
    env_file:
      - ./hadoop.env

  project-historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: project-historyserver
    depends_on:
      - project-namenode
      - project-datanode1
      - project-datanode2
      - project-datanode3
    networks:
      - "project-net"
    volumes:
      - project_hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env

  project-nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: project-nodemanager
    depends_on:
      - project-namenode
      - project-datanode1
      - project-datanode2
      - project-datanode3
    networks:
      - "project-net"
    env_file:
      - ./hadoop.env

  project-datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: project-datanode1
    depends_on:
      - project-namenode
    networks:
        - "project-net"
    volumes:
      - project_hadoop_datanode1:/hadoop/dfs/data
    env_file:
      - ./hadoop.env

  project-datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: project-datanode2
    depends_on:
      - project-namenode
    networks:
        - "project-net"
    volumes:
      - project_hadoop_datanode2:/hadoop/dfs/data
    env_file:
      - ./hadoop.env

  project-datanode3:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: project-datanode3
    depends_on:
      - project-namenode
    networks:
        - "project-net"
    volumes:
      - project_hadoop_datanode3:/hadoop/dfs/data
    env_file:
      - ./hadoop.env

  project-spark-master:
    image: bde2020/spark-master:3.0.0-hadoop3.2
    container_name: project-spark-master
    depends_on:
        - project-namenode
    networks:
        - "project-net"
    ports:
        - "18080:8080"  # 避免与 cca3 冲突
        - "17077:7077"  # 避免与 cca3 冲突
    environment:
        - INIT_DAEMON_STEP=setup_spark
        - NAMENODE_HOSTNAME=project-namenode
  
  project-spark-worker-1:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: project-spark-worker-1
    depends_on:
        - project-spark-master
        - project-namenode
    networks:
        - "project-net"
    ports:
        - "18081:8081"  # 避免与 cca3 冲突
    environment:
        - "SPARK_MASTER=spark://project-spark-master:7077"            
        - SPARK_WORKER_CORES=1
        - SPARK_WORKER_MEMORY=512m
        - NAMENODE_HOSTNAME=project-namenode

  project-spark-worker-2:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: project-spark-worker-2
    depends_on:
        - project-spark-master
        - project-namenode
    networks:
        - "project-net"
    ports:
        - "18082:8082"  # 避免与 cca3 冲突
    environment:
        - "SPARK_MASTER=spark://project-spark-master:7077"            
        - SPARK_WORKER_CORES=1
        - SPARK_WORKER_MEMORY=512m
        - NAMENODE_HOSTNAME=project-namenode
  
  project-jupyter-notebook:
    container_name: project-jupyternb
    image: jupyter/all-spark-notebook:42f4c82a07ff
    depends_on:
        - project-spark-master
    expose:
        - "18888"  # 避免与 cca3 冲突
    networks:
        - "project-net"
    user: root
    ports:
        - "18888:8888"  # 避免与 cca3 冲突
    volumes:
        - ./data:/home/jovyan/work/data  # 挂载 data 文件夹
        - ./events:/tmp/spark-events
    command: bash -c "pip install gdown faiss-cpu && cp /home/jovyan/work/data/cardio_train.csv /home/jovyan/work/data && start-notebook.sh --ip=0.0.0.0 --allow-root --NotebookApp.token=''"
