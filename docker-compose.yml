version: "3.3"

volumes:
    project_namenode:
    project_datanode1:
    project_datanode2:
    project_datanode3:
    project_historyserver:
    project_data:

networks:
    project-net:
        driver: bridge

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: project_namenode
    networks:
      - "project-net"
    ports:
      - 9871:9870  # 修改后的NameNode Web UI端口，避免与cca3冲突
      - 9001:9000  # 修改后的NameNode HDFS端口，避免与cca3冲突
    volumes:
      - project_namenode:/hadoop/dfs/name
      - ./data:/home/data
    environment:
      - CLUSTER_NAME=project-cluster
    env_file:
      - ./hadoop_project.env

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: project_resourcemanager
    depends_on:
      - namenode
      - datanode1
      - datanode2
      - datanode3
    networks:
      - "project-net"
    ports:
      - 8090:8088  # 修改后的ResourceManager端口，避免与cca3冲突
    env_file:
      - ./hadoop_project.env

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: project_historyserver
    depends_on:
      - namenode
      - datanode1
      - datanode2
      - datanode3
    networks:
      - "project-net"
    volumes:
      - project_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop_project.env

  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: project_nodemanager1
    depends_on:
      - namenode
      - datanode1
      - datanode2
      - datanode3
    networks:
      - "project-net"
    env_file:
      - ./hadoop_project.env

  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: project_datanode1
    depends_on:
      - namenode
    networks:
        - "project-net"
    volumes:
      - project_datanode1:/hadoop/dfs/data
    env_file:
      - ./hadoop_project.env

  datanode2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: project_datanode2
    depends_on:
      - namenode
    networks:
        - "project-net"
    volumes:
      - project_datanode2:/hadoop/dfs/data
    env_file:
      - ./hadoop_project.env

  datanode3:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: project_datanode3
    depends_on:
      - namenode
    networks:
        - "project-net"
    volumes:
      - project_datanode3:/hadoop/dfs/data
    env_file:
      - ./hadoop_project.env

  spark-master:
    image: bde2020/spark-master:3.0.0-hadoop3.2
    container_name: project_spark-master
    depends_on:
        - namenode
    networks:
        - "project-net"
    ports:
        - "8083:8080"  # Spark Master Web UI端口，避免与cca3冲突
        - "7078:7077"  # Spark Master通信端口
    environment:
        - INIT_DAEMON_STEP=setup_spark
        - NAMENODE_HOSTNAME=project_namenode
  
  spark-worker-1:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: project_spark-worker-1
    depends_on:
        - spark-master
        - namenode
    networks:
        - "project-net"
    ports:
        - "8084:8081"  # Spark Worker 1 Web UI端口，避免与cca3冲突
    environment:
        - "SPARK_MASTER=spark://project_spark-master:7077"            
        - SPARK_WORKER_CORES=1
        - SPARK_WORKER_MEMORY=512m
        - NAMENODE_HOSTNAME=project_namenode

  spark-worker-2:
    image: bde2020/spark-worker:3.0.0-hadoop3.2
    container_name: project_spark-worker-2
    depends_on:
        - spark-master
        - namenode
    networks:
        - "project-net"
    ports:
        - "8085:8082"  # Spark Worker 2 Web UI端口，避免与cca3冲突
    environment:
        - "SPARK_MASTER=spark://project_spark-master:7077"            
        - SPARK_WORKER_CORES=1
        - SPARK_WORKER_MEMORY=512m
        - NAMENODE_HOSTNAME=project_namenode
  
  jupyter-notebook:
    container_name: project_jupyternb
    image: jupyter/all-spark-notebook:42f4c82a07ff
    depends_on:
        - spark-master
    expose:
        - "8889"  # 修改后的Jupyter端口，避免与cca3冲突
    networks:
        - "project-net"
    user: root
    ports:
        - "8889:8888"
    volumes:
        - ./data:/home/jovyan/work/data  # 挂载你本地的data目录，包含cardio_train.csv
    command: bash -c "pip install gdown faiss-cpu && cp /home/jovyan/work/data/cardio_train.csv /home/jovyan/work/data && start-notebook.sh --ip=0.0.0.0 --allow-root --NotebookApp.token=''"
